# 应用程序tomcat容器监听的http端口号
server:
  port: 8001

# spring 配置
spring:
  application:
    name: rhythm
  boot:
    admin:
      client:
        url: http://localhost:8002
  # 数据源配置
  datasource:
    # JDBC驱动类签名
    driverClassName: com.mysql.cj.jdbc.Driver
    # 连接数据库URL路径
    url: jdbc:mysql://${db.url}/rhythm?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
    # 数据库账户名称
    username: ${db.username}
    # 数据库账户密码
    password: ${db.password}
    # 获取Connection连接对象的类签名
    type: com.alibaba.druid.pool.DruidDataSource
  web:
    resources:
      # 覆盖默认的静态资源存放目录
      static-locations: classpath:/static/
  mvc:
    static-path-pattern: /static/**

  # Redis配置
  redis:
    # Redis部署Ip地址
    host: ${redisConfig.host}
    # Redis监听端口
    port: 6379
    # Redis登录密码
    password: ${redisConfig.password}

  # kafka 配置
  kafka:
    # kafka 服务节点网络域
    bootstrap-servers: ${kafkaConfig.bootstrap-servers}:9092
    # 生产者 配置
    producer:
      # 重试次数
      retries: 3
      # 批量发送数据大小
      batch-size: 16384
      # 缓冲数据大小
      buffer-memory: 33554432
      # 回执数 / 即假设消息超时, (auto-offset-reset: earliest)立即重新; 如果预定时间内未获取到consumer回执, 即消息超时; 有时, 一个消息包含多个业务操作,即n个consummer,即n个回执, 如果  只有获取n个回执,该消息已读即该消息消费  回执与分布式事务
      acks: 1
      # key数据 对象序列化 类签名 / 消息存储到队列, 是java对象序列化为string存储到消息队列
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # value数据 对象序列化 类签名
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者 配置
    consumer:
      # 消费者分组id; consummer订阅消息队列group-01
      # group-id 是消费者组的标识符，用于将多个消费者组合起来，共同消费订阅的主题（topic）中的消息。
      # 一个消费者组中的每个消费者都消费topic的一部分分区(一部分消息)，从而能够并行消费消息(消息的负载均衡)，提高消费性能。
      group-id: group-01,my-group
      # 启用自动提交回执 回执与分布式事务
      enable-auto-commit: false
      # 重置消费队列指针策略 / 即假设消息超时, 消息队列池立即重新尝试再次读取消费运行该消息;而非
      auto-offset-reset: earliest
      # key数据 对象反序列化 类签名 / 读取消息, string反序列化为java对象
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # value数据 对象反序列化 类签名
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 队列池中的最大记录数
      max-poll-records: 500
    # 监听器 配置
    listener:
      # 回执模式：手动回执模式
      ack-mode: MANUAL_IMMEDIATE

logging:
  level:
    com.test: trace

# mybatis配置
mybatis:
  # 映射文件表达式
  mapper-locations: classpath:mapper/*Mapper.xml


mybatis-plus:
  mapper-locations: classpath:mapper/*Mapper.xml
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl


# PageHelper 配置
pagehelper:
  helperDialect: mysql
  reasonable: true
  supportMethodsArguments: true
  params=count: countSql


management:
  endpoints:
    web:
      exposure:
        include: "*"
      cors:
        allowedOrigins: ${actuatorConfig.allowedOrigins}
        allowed-methods: GET,POST
  # 配置显示健康检查详细信息
  endpoint:
    health:
      show-details: always


springfox:
  documentation:
    swagger:
      v2:
        host:
    swagger-ui:
      base-url: